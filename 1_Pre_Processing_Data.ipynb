{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#kimlik doğrulama işlemi :drive in içinde çalışma ortamı sağlarız serverlarda\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "metadata": {
        "id": "TXNhnD-KmwH8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9d9bbc1-fe87-4403-9779-79bfec969a18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXnRrKGUmhjK",
        "outputId": "47640535-1ce1-4a81-d218-d21ec56e2161"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9}\n",
            "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
          ]
        }
      ],
      "source": [
        "# DATA PRE-PROCESSING \n",
        "\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "data_path=r'./MyDrive/Urban_Sounds_Classification/spectrograms/'\n",
        "\n",
        "categories=sorted(os.listdir(data_path))\n",
        "\n",
        "labels=[i for i in range(len(categories))]\n",
        "label_dict=dict(zip(categories,labels))\n",
        "\n",
        "print(label_dict)\n",
        "print(categories)\n",
        "print(labels)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RESIZING AND CONVERTING IMAGES TO GRAYSCALE\n",
        "\n",
        "img_size=100\n",
        "data=[]\n",
        "target=[]\n",
        "from skimage import io\n",
        "for category in categories:\n",
        "    folder_path=os.path.join(data_path,category)\n",
        "    img_names=os.listdir(folder_path)        \n",
        "    for img_name in img_names:\n",
        "        img_path=os.path.join(folder_path,img_name)\n",
        "#         img=cv2.imread(img_path)\n",
        "        img = io.imread(img_path)\n",
        "        try:\n",
        "            gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)           \n",
        "            #Coverting the image into gray scale\n",
        "            resized=cv2.resize(gray,(img_size,img_size))\n",
        "            #resizing the gray scale into 100x100, since we need a fixed common size for all the images in the dataset\n",
        "            data.append(resized)\n",
        "            target.append(label_dict[category])\n",
        "            #appending the image and the label(categorized) into the list (dataset)\n",
        "        except Exception as e:\n",
        "            print('Exception:',e)\n",
        "            #if any exception rasied, the exception will be printed here. And pass to the next image"
      ],
      "metadata": {
        "id": "lFb-K090nCJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "data=np.array(data)/255.0\n",
        "data=np.reshape(data,(data.shape[0],img_size,img_size,1))\n",
        "target=np.array(target)\n",
        "import keras\n",
        "\n",
        "from keras.utils import np_utils\n",
        "new_target=np_utils.to_categorical(target)"
      ],
      "metadata": {
        "id": "YvjB8WYWo00G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# First, create X_train, y_train and X_temporary and y_temporary datasets from X and y.\n",
        "X_train,X_temporary,y_train,y_temporary = train_test_split(data,new_target,test_size=0.2)\n",
        "\n",
        "# Using the X_temporary and y_temporary dataset we just created create validaiton and test datasets.\n",
        "X_val , X_test , y_val , y_test = train_test_split(X_temporary,y_temporary,test_size=0.5)"
      ],
      "metadata": {
        "id": "c70Y04CUo5XL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the lengths of the X, X_train, X_val and X_test\n",
        "print(f'Length of the dataset : {len(data)}')\n",
        "print(f'Length of the training dataset : {len(X_train)}')\n",
        "print(f'Length of the validation dataset : {len(X_val)}')\n",
        "print(f'Length of the test dataset : {len(X_test)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHcDrxDqy2uU",
        "outputId": "402f37fd-deb9-4436-afbd-5603dcd75284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of the dataset : 8734\n",
            "Length of the training dataset : 6987\n",
            "Length of the validation dataset : 873\n",
            "Length of the test dataset : 874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the data and target\n",
        "\n",
        "np.save('./MyDrive/Urban_Sounds_Classification/X_train.npy',X_train)\n",
        "np.save('./MyDrive/Urban_Sounds_Classification/y_train.npy',y_train)\n",
        "np.save('./MyDrive/Urban_Sounds_Classification/X_val.npy',X_val)\n",
        "np.save('./MyDrive/Urban_Sounds_Classification/X_test.npy',X_test)\n",
        "np.save('./MyDrive/Urban_Sounds_Classification/y_val.npy',y_val)\n",
        "np.save('./MyDrive/Urban_Sounds_Classification/y_test.npy',y_test)\n"
      ],
      "metadata": {
        "id": "zay6t1BgzBQ_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}